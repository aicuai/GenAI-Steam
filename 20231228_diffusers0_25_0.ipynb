{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicuai/GenAI-Steam/blob/main/20231228_diffusers0_25_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# diffusers-0.25.0ã®æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ\n",
        "\n",
        "T4 GPUä»¥ä¸Šã§å‹•ãã¾ã™\n",
        "\n",
        "https://github.com/huggingface/diffusers/releases/tag/v0.25.0\n",
        "\n",
        "https://note.com/o_ob/n/nf7869b5974e4\n",
        "\n"
      ],
      "metadata": {
        "id": "kGvJ9UffMnao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# aMUSEd\n",
        "\n",
        "aMUSEd ã¯ã€MUSE ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ã„ãŸè»½é‡ã® *TextToImageãƒ¢ãƒ‡ãƒ«* ã§ã™ã€‚\n",
        "aMUSEd ã¯ã€ä¸€åº¦ã«å¤šãã®ç”»åƒã‚’ç´ æ—©ãç”Ÿæˆã™ã‚‹ãªã©ã€è»½é‡ã§é«˜é€Ÿãªãƒ¢ãƒ‡ãƒ«ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ç‰¹ã«å½¹ç«‹ã¡ã¾ã™ã€‚ aMUSEd ã¯ç¾åœ¨ç ”ç©¶ãƒªãƒªãƒ¼ã‚¹ã§ã™ã€‚\n",
        "\n",
        "aMUSEd ã¯ã€å¤šãã® diffusion ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å°‘ãªã„é †æ–¹å‘ãƒ‘ã‚¹ã§ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ç”Ÿæˆã§ãã‚‹ VQVAE ãƒˆãƒ¼ã‚¯ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã§ã™ã€‚ MUSE ã¨ã¯å¯¾ç…§çš„ã«ã€T5-XXL ã®ä»£ã‚ã‚Šã«å°å‹ã®ãƒ†ã‚­ã‚¹ãƒˆ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ CLIP-L/14 ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ ammused ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå°‘ãªãã€ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ ãƒ‘ã‚¹ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ãŒå°‘ãªã„ãŸã‚ã€å¤šãã®ç”»åƒã‚’è¿…é€Ÿã«ç”Ÿæˆã§ãã¾ã™ã€‚ ã“ã®åˆ©ç‚¹ã¯ã€ç‰¹ã«å¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã§è¦‹ã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "## Text-to-image generation\n",
        "\n",
        "```\n",
        "import torch\n",
        "from diffusers import AmusedPipeline\n",
        "\n",
        "pipe = AmusedPipeline.from_pretrained(\n",
        "    \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"cowboy\"\n",
        "image = pipe(prompt, generator=torch.manual_seed(8)).images[0]\n",
        "image.save(\"text2image_512.png\")\n",
        "Image-to-image generation\n",
        "\n",
        "import torch\n",
        "from diffusers import AmusedImg2ImgPipeline\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "pipe = AmusedImg2ImgPipeline.from_pretrained(\n",
        "    \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"apple watercolor\"\n",
        "input_image = (\n",
        "    load_image(\n",
        "        \"https://raw.githubusercontent.com/huggingface/amused/main/assets/image2image_256_orig.png\"\n",
        "    )\n",
        "    .resize((512, 512))\n",
        "    .convert(\"RGB\")\n",
        ")\n",
        "\n",
        "image = pipe(prompt, input_image, strength=0.7, generator=torch.manual_seed(3)).images[0]\n",
        "image.save(\"image2image_512.png\")\n",
        "```\n",
        "\n",
        "## Inpainting\n",
        "```\n",
        "import torch\n",
        "from diffusers import AmusedInpaintPipeline\n",
        "from diffusers.utils import load_image\n",
        "from PIL import Image\n",
        "\n",
        "pipe = AmusedInpaintPipeline.from_pretrained(\n",
        "    \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"a man with glasses\"\n",
        "input_image = (\n",
        "    load_image(\n",
        "        \"https://raw.githubusercontent.com/huggingface/amused/main/assets/inpainting_256_orig.png\"\n",
        "    )\n",
        "    .resize((512, 512))\n",
        "    .convert(\"RGB\")\n",
        ")\n",
        "mask = (\n",
        "    load_image(\n",
        "        \"https://raw.githubusercontent.com/huggingface/amused/main/assets/inpainting_256_mask.png\"\n",
        "    )\n",
        "    .resize((512, 512))\n",
        "    .convert(\"L\")\n",
        ")    \n",
        "\n",
        "image = pipe(prompt, input_image, mask, generator=torch.manual_seed(3)).images[0]\n",
        "image.save(f\"inpainting_512.png\")\n",
        "```\n",
        "ğŸ“œ Docs: https://huggingface.co/docs/diffusers/main/en/api/pipelines/amused\n",
        "\n",
        "ğŸ› ï¸ Models:\n",
        "\n",
        "- amused-256: https://huggingface.co/amused/amused-256 (603M params)\n",
        "- amused-512: https://huggingface.co/amused/amused-512 (608M params)\n",
        "\n"
      ],
      "metadata": {
        "id": "LoutoEHCNtfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "zvbZy1bLwuKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 3 å€é«˜é€Ÿãª SDXL\n",
        "\n",
        "TextToImage ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã‚‹ä¸€é€£ã®æœ€é©åŒ–æ‰‹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã¯ã™ã¹ã¦ã€è¿½åŠ ã® C++ ã‚³ãƒ¼ãƒ‰ã‚’å¿…è¦ã¨ã›ãšã«ãƒã‚¤ãƒ†ã‚£ãƒ– PyTorch ã§å®Ÿè¡Œã§ãã¾ã™ã€‚\n",
        "\n",
        "![](https://github.com/huggingface/diffusers/assets/22957388/36d6cf13-5794-4332-b197-b07c279935a1)\n",
        "\n",
        "ã“ã‚Œã‚‰ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã¯ Stable Diffusion XL (SDXL) ã«å›ºæœ‰ã®ã‚‚ã®ã§ã¯ãªãã€ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã‚‚ä½¿ç”¨ã§ãã¾ã™ã€‚ ä»¥ä¸‹ã«æä¾›ã•ã‚Œã‚‹è©³ç´°ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n",
        "\n",
        "ğŸ“œ Docs: https://huggingface.co/docs/diffusers/main/en/tutorials/fast_diffusion\n"
      ],
      "metadata": {
        "id": "GRsSC0_wObOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ä¸­æ–­å¯èƒ½ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\n",
        "\n",
        "Diffusionãƒ—ãƒ­ã‚»ã‚¹ã®ä¸­æ–­ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¸­é–“çµæœã«æº€è¶³ã§ããªã„å ´åˆã«ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ã§ãã‚‹ãŸã‚ã€ãƒ‡ã‚£ãƒ•ãƒ¥ãƒ¼ã‚¶ãƒ¼ã§å‹•ä½œã™ã‚‹ UI ã‚’æ§‹ç¯‰ã™ã‚‹å ´åˆã«ç‰¹ã«ä¾¿åˆ©ã§ã™ã€‚ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ã“ã‚Œã‚’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
        "\n",
        "ã“ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã¯ã€pipeã€iã€tã€ãŠã‚ˆã³ callback_kwargs ã®å¼•æ•°ã‚’å–ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ (ã“ã‚Œã¯è¿”ã•ã‚Œã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™)ã€‚ ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®å¾Œã«æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ã™ã‚‹ã«ã¯ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã® _interrupt å±æ€§ã‚’ True ã«è¨­å®šã—ã¾ã™ã€‚ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å†…ã«ç‹¬è‡ªã®ã‚«ã‚¹ã‚¿ãƒ åœæ­¢ãƒ­ã‚¸ãƒƒã‚¯ã‚’è‡ªç”±ã«å®Ÿè£…ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n",
        "\n",
        "ã“ã®ä¾‹ã§ã¯ã€num_inference_steps ãŒ 50 ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã¯ 10 ã‚¹ãƒ†ãƒƒãƒ—å¾Œã«åœæ­¢ã—ã¾ã™ã€‚\n",
        "\n",
        "```\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "pipe.enable_model_cpu_offload()\n",
        "num_inference_steps = 50\n",
        "\n",
        "def interrupt_callback(pipe, i, t, callback_kwargs):\n",
        "    stop_idx = 10\n",
        "    if i == stop_idx:\n",
        "        pipe._interrupt = True\n",
        "\n",
        "    return callback_kwargs\n",
        "\n",
        "pipe(\n",
        "    \"A photo of a cat\",\n",
        "    num_inference_steps=num_inference_steps,\n",
        "    callback_on_step_end=interrupt_callback,\n",
        ")\n",
        "```\n",
        "ğŸ“œ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: https://huggingface.co/docs/diffusers/main/en/using-diffusers/callback\n",
        "\n",
        "LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¾‹ã«ãŠã‘ã‚‹ãƒšãƒ•ãƒˆ\n",
        "LoRA ã«é–¢ã—ã¦å…¬å¼ã«ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã« peft ã‚’çµ„ã¿è¾¼ã¿ã¾ã—ãŸã€‚ ã“ã‚Œã«ã‚ˆã‚Šã‚³ãƒ¼ãƒ‰ãŒå¤§å¹…ã«ç°¡ç´ åŒ–ã•ã‚Œã€å¯èª­æ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚ peft ã®ãŠã‹ã’ã§ã€LoRA ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã•ã‚‰ã«ç°¡å˜ã«ãªã‚Šã¾ã—ãŸã€‚\n",
        "\n",
        "## LCM LoRA SDXL ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚ˆã‚Šãƒ¡ãƒ¢ãƒªã«å„ªã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³\n",
        "\n",
        "peft ã®ãƒ™ã‚¹ãƒˆ ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’å–ã‚Šå…¥ã‚Œã¦ã€SDXL ã® LCM LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚ˆã‚Šãƒ¡ãƒ¢ãƒªã«å„ªã—ã„ã‚‚ã®ã«ã—ã¾ã—ãŸã€‚ ãã®ãŸã‚ã€2 ã¤ã® UNet (æ•™å¸«ã¨ç”Ÿå¾’) ã‚’åˆæœŸåŒ–ã™ã‚‹å¿…è¦ã¯ãªããªã‚Šã¾ã—ãŸã€‚ ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã¯ã€è¿…é€Ÿãªå®Ÿé¨“ã®ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚‚çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚ è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/README_sdxl.md)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      ],
      "metadata": {
        "id": "sm_rcCzONHHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import AmusedPipeline\n",
        "\n",
        "pipe = AmusedPipeline.from_pretrained(\n",
        "    \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"miku\"\n",
        "image = pipe(prompt, generator=torch.manual_seed(39)).images[0]\n",
        "image.save(\"miku.png\")"
      ],
      "metadata": {
        "id": "LQO4SwPJ3kVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import AmusedPipeline\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipe = AmusedPipeline.from_pretrained(\n",
        "    \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe.vqvae.to(torch.float32)  # Fix for vqvae producing NaNs in fp16\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Define your prompt\n",
        "num_images = 9\n",
        "prompt = \"miku in dancing\"\n",
        "for i in range(num_images):\n",
        "    image = pipe(prompt, generator=torch.manual_seed(i)).images[0]\n",
        "    image.save(f\"miku_in_dancing{i}.png\")\n"
      ],
      "metadata": {
        "id": "oaqbfpYm2thv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlRllIt6wWZg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import AmusedImg2ImgPipeline\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "pipe = AmusedImg2ImgPipeline.from_pretrained(\n",
        "    \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"apple watercolor\"\n",
        "input_image = (\n",
        "    load_image(\n",
        "        \"miku_39.png\"\n",
        "    )\n",
        "    .resize((512, 512))\n",
        "    .convert(\"RGB\")\n",
        ")\n",
        "\n",
        "image = pipe(prompt, input_image, strength=0.7, generator=torch.manual_seed(39)).images[0]\n",
        "image.save(\"image2image_512.png\")"
      ]
    }
  ]
}